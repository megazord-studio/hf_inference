[project]
name = "hf-inference"
version = "0.1.0"
description = "A unified FastAPI server for Hugging Face model inference across 31+ tasks"
readme = { file = "README.md", content-type = "text/markdown" }
requires-python = ">=3.12,<3.13"
license = { file = "LICENSE" }
authors = [
  { name = "megazord.studio GmbH", email = "info@megazord.studio" }
]
maintainers = [
  { name = "megazord.studio GmbH", email = "info@megazord.studio" }
]
classifiers = [
  "Development Status :: 3 - Alpha",
  "Intended Audience :: Developers",
  "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
  "Programming Language :: Python",
  "Programming Language :: Python :: 3",
  "Programming Language :: Python :: 3.12",
  "Programming Language :: Python :: 3 :: Only",
  "Framework :: FastAPI",
  "Topic :: Scientific/Engineering :: Artificial Intelligence",
  "Topic :: Software Development :: Libraries",
]
keywords = ["huggingface", "transformers", "diffusers", "fastapi", "inference", "ml", "ai"]
dependencies = [
  "transformers~=4.57",
  "diffusers~=0.35",
  "huggingface-hub~=0.35",
  "accelerate~=1.0",
  "sentence-transformers~=5.1",
  "torch~=2.8.0",
  "torchvision~=0.23.0",
  "safetensors~=0.6",
  "pillow~=11.3",
  "numpy>=1.15.0,<2.0.0", # pyctcdecode 0.5 requires numpy<2
  "pandas~=2.3",
  "timm~=1.0",
  "einops~=0.8",
  "pydantic~=2.12",
  "protobuf~=6.32",
  "soundfile~=0.13",
  "sacremoses~=0.1",
  "sentencepiece~=0.2",
  "pytesseract~=0.3",
  "emoji~=2.15",
  "pyctcdecode~=0.5",
  "fastapi~=0.119",
  "uvicorn~=0.37",
  "python-multipart~=0.0.20",
  "av~=16.0",
  "hf-transfer>=0.1.9",
  "Jinja2~=3.1",
  "whisper>=1.1.10",
  "onnxruntime~=1.18",
  "sse-starlette~=1.6",
  "torchaudio~=2.8.0",
  "librosa~=0.10",
  "ultralytics~=8.3",
  "peft>=0.18.0",
  "tiktoken>=0.12.0",
  "transformers-stream-generator>=0.0.5",
  "xformers>=0.0.32.post2",
  "easyocr>=1.7.2",
  "trimesh>=4.10.0",
  "speechbrain>=1.0.3",
  "addict>=2.4.0",
  "coqui-tts>=0.27.1",
  "easydict>=1.13",
]

[project.urls]
Homepage = "https://github.com/megazord-studio/hf_inference"
Repository = "https://github.com/megazord-studio/hf_inference"
Issues = "https://github.com/megazord-studio/hf_inference/issues"
Changelog = "https://github.com/megazord-studio/hf_inference/blob/main/CHANGELOG.md"

[project.optional-dependencies]
dev = [
  "pytest",
  "pytest-asyncio",
  "httpx",
  "ruff",
  "mypy",
  "poethepoet",
  "mdformat",
  "bandit",
  "vulture",
  "radon",
]

[project.scripts]
# CLI entrypoint to run the server: `hf-inference`
"hf-inference" = "app.main:main"

[tool.poe.tasks]
# Run tasks with: uv run poe <task>
# e.g. uv run poe test
test = { shell = "APP_REGISTRY_MEMORY_LIMIT_MB=45000 uv run pytest -ra -vvv --log-cli-level=INFO || exit 1" }
format = { shell = '''
uv run ruff format || exit 1
uv run ruff check --fix || exit 1
uv run mdformat . || exit 1
''' }
types = { shell = "uv run mypy" }
security = { shell = "uv run bandit -r app --severity-level high" }
complexity = { shell = "uv run radon cc -s -a app" }
deadcode = { shell = "uv run vulture app tests" }
dev = { shell = "uvicorn app.main:app --reload" }
generate-contracts = { shell = "python scripts/generate_contracts.py" }

[tool.ruff]
line-length = 79

[tool.ruff.lint]
select = ["E", "F", "W", "Q", "I"]
ignore = ["E501"]

[tool.ruff.lint.isort]
force-single-line = true

[tool.mypy]
python_version = "3.12"
files = [
  "app/**/*.py",
]
ignore_missing_imports = true
disallow_untyped_defs = true
check_untyped_defs = true
warn_unused_ignores = true
show_error_codes = true

[tool.hatch.build]
include = [
  "README.md",
  "LICENSE",
]

[build-system]
requires = ["hatchling>=1.25"]
build-backend = "hatchling.build"

# For source distributions, include tests and assets for reference
[tool.hatch.build.targets.sdist]
include = [
  "app/**",
  "assets/**",
  "tests/**",
  "README.md",
  "LICENSE",
  "pyproject.toml",
  "Dockerfile",
]
